# Assessment Methods Aligned to Bloom's Taxonomy

## Overview

Effective assessment methods align with the cognitive level of the learning objective. This document maps Bloom's levels to appropriate assessment strategies.

---

## Level 1: Remember - Assessment Methods

**Objective Type**: Recall facts and basic terminology

### Assessment Methods

**Multiple Choice (Factual)**
- List four Python built-in functions; select the correct one
- "Which keyword defines a class?" → Options: def, class, struct, type

**Short Answer / Fill-in-the-Blank**
- "What is the Python operator for integer division?" → Answer: //
- "Name three data types in Python" → Answer: int, str, list, ...

**Matching**
- Match Python keywords to their purposes
- Match data type names to examples

**Flashcard / Vocabulary Quiz**
- Term definitions
- Syntax examples
- Quick recognition exercises

### Scoring
- Objective: Right/wrong only
- Difficulty: Low (5-10 minutes per assessment)

---

## Level 2: Understand - Assessment Methods

**Objective Type**: Explain, describe, interpret concepts

### Assessment Methods

**Short Explanation Essays**
- "Explain the difference between == and is in Python"
- "Describe how a for loop works" (2-3 sentences)

**Concept Mapping**
- Explain relationships between concepts
- Example: Describe relationships between class, instance, method, attribute

**Paraphrasing / Code Walkthroughs**
- Learner explains what existing code does line-by-line
- Learner describes what function will return before running it

**Comparison Questions**
- "Compare lists and tuples: similarities and differences"
- "What's the difference between local and global scope?"

**Example Generation**
- "Provide an example of a list comprehension"
- "Write an example of a function call"

### Scoring
- Rubric-based (is explanation clear? accurate? uses right terminology?)
- Difficulty: Medium (10-15 minutes per assessment)

---

## Level 3: Apply - Assessment Methods

**Objective Type**: Use knowledge to solve problems or implement procedures

### Assessment Methods

**Guided Code Writing (Scaffolded)**
- Complete-the-function exercises
- Template-based coding where learner fills in missing parts
- "Write a function that takes a number and returns true if even"

**Debugging Exercises**
- Fix broken code following provided error messages
- Limited to applying known patterns

**Practical Coding Labs**
- Implement a feature with step-by-step requirements
- "Write code to read a CSV file and print the number of rows"

**Algorithm Implementation from Pseudocode**
- Given pseudocode, implement in Python
- Following a provided algorithm exactly

**Problem Sets**
- Series of related problems of increasing difficulty
- Learners apply same pattern in different contexts

### Scoring
- Functional correctness (does code work?)
- Code quality (is it readable? follows conventions?)
- Completeness (does it meet all requirements?)
- Difficulty: Medium-High (20-45 minutes per assessment)

---

## Level 4: Analyze - Assessment Methods

**Objective Type**: Break down and examine structure, relationships, and logic

### Assessment Methods

**Code Analysis Essays**
- Analyze provided code for structure, efficiency, design choices
- "Examine this code. What is its time complexity? Why might an alternative approach be better?"

**Pattern Identification**
- Identify design patterns in code examples
- "Which design pattern is used here? How do you know?"

**Algorithm Comparison**
- Compare multiple implementations by analyzing tradeoffs
- "Compare bubble sort vs quicksort. What are advantages/disadvantages?"

**Annotated Code Reviews**
- Learner reviews code and marks up with analysis
- Identify bottlenecks, design issues, clarity problems

**Architecture Analysis**
- Explain data flow, class hierarchies, or system components
- Justify organizational choices

**Tradeoff Analysis**
- "Given these requirements, would you use a list or tuple? Justify."
- "Why use recursion here instead of a loop?"

### Scoring
- Depth of analysis (identified all important factors?)
- Accuracy of reasoning (is logic sound?)
- Completeness (all important aspects covered?)
- Difficulty: High (30-60 minutes per assessment)

---

## Level 5: Evaluate - Assessment Methods

**Objective Type**: Make judgments based on criteria and standards

### Assessment Methods

**Code Reviews and Critique**
- Evaluate submitted code on readability, efficiency, maintainability
- Provide justification for improvements

**Design Justification Essay**
- "Justify why you chose this algorithm over alternatives"
- "Defend your class design against these requirements"

**Security / Performance Audit**
- Evaluate code for security vulnerabilities or performance issues
- "Identify all security issues in this code. Rate their severity."

**Test Adequacy Assessment**
- Review test suite
- "Is test coverage adequate for this function? Why or why not?"

**Peer Review Assignments**
- Learners review classmate's code and provide constructive feedback
- Use rubric to standardize evaluation

**Standards-Based Evaluation**
- Evaluate code against style guide (PEP 8), design principles, best practices
- "Does this code follow our team's standards? Where does it fall short?"

### Scoring
- Quality of justification (is reasoning solid?)
- Appropriate use of criteria (using right standards?)
- Fairness (are judgments defensible?)
- Difficulty: High (45-90 minutes per assessment)

---

## Level 6: Create - Assessment Methods

**Objective Type**: Design new solutions and combine elements in original ways

### Assessment Methods

**Open-Ended Projects**
- Design and implement a complete application from requirements
- Learner makes architectural decisions
- Example: "Build a task management application with these features"

**Capstone Assessments**
- Major project integrating multiple skills
- Real-world or semi-realistic problem
- Requires design document + implementation + testing

**Algorithm Design Challenges**
- "Create an algorithm to solve this problem" (not from examples)
- Learner invents approach, not just applies template

**Architecture Design Exercises**
- "Design the architecture for this system"
- Document your design, justify choices

**Framework/Library Creation**
- Build reusable code components
- Document for other developers to use

**Competitive Programming**
- LeetCode, CodeWars, or similar platforms
- Learner solves novel problems using learned concepts

**Portfolio Projects**
- Collection of work demonstrating mastery
- Can include personal projects
- Reflection on what was learned

### Scoring
- Correctness of solution
- Appropriateness to problem constraints
- Code quality (readability, efficiency, maintainability)
- Completeness of design documentation
- Originality / cleverness of approach
- Difficulty: Very High (several hours to weeks, depending on scope)

---

## Matching Objectives to Assessment Methods

### Quick Reference Table

| Bloom's Level | Objective Type | Good Assessments | Time | Effort |
|---|---|---|---|---|
| Remember | Recall facts | Multiple choice, flashcards | 5-10 min | Low |
| Understand | Explain concepts | Essays, explanations, comparisons | 10-15 min | Low-Medium |
| Apply | Use to solve problems | Code exercises, labs, problems | 20-45 min | Medium |
| Analyze | Break down structure | Code analysis, comparisons | 30-60 min | Medium-High |
| Evaluate | Judge quality | Code reviews, audits, justifications | 45-90 min | High |
| Create | Design original solutions | Projects, capstones, architecture design | Hours-weeks | Very High |

---

## Mixing Assessment Methods

### Principle: Use Multiple Methods
A single objective might be assessed through:
1. **Formative** (during learning): Code-along, quick check, self-check
2. **Summative** (end of unit): Final project, exam question, portfolio piece

### Example: "Implement a sorting algorithm"
- **Formative**: Guided coding exercise with template
- **Summative**: Implement algorithm from scratch + compare with built-in sort

---

## Balancing Assessment Depth

### Not All Assessments Need to Be Complex
- Remember/Understand: Quick quizzes are fine (1 question each)
- Apply: Medium exercises (few at a time)
- Analyze/Evaluate/Create: Major assessments (fewer but substantial)

### Cognitive Load Principle
- Too many mini-assessments → overwhelm learners
- Too few assessments → no feedback for improvement
- **Sweet spot**: Mix quick checks + periodic deeper assessments

---

## Red Flags: Misaligned Assessment

### Problem 1: Assessment Too Easy
- Testing Remember when objective is Apply
- *Fix*: Use assessment from Apply column

### Problem 2: Assessment Too Hard
- Testing Create when objective is Understand
- *Fix*: Use assessment from Understand column

### Problem 3: Ambiguous Assessment
- Objective unclear what "meets criteria" means
- *Fix*: Add rubric or example of good answer

### Problem 4: All Essays, No Coding
- Testing explanation but not application
- *Fix*: Add code-based assessments

---

## Summary

**Good assessment**:
- ✅ Directly measures the objective
- ✅ Uses method appropriate for cognitive level
- ✅ Clear criteria for success
- ✅ Reasonable time/effort from learner
- ✅ Provides actionable feedback

**Bad assessment**:
- ❌ Doesn't match cognitive level (asks learner to create when objective is remember)
- ❌ Unclear what "correct" means
- ❌ Takes way too long or is trivial
- ❌ No feedback for improvement
